{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2EpQW3E84Ya"
   },
   "source": [
    "# **Exercicio Duelo de Modelos 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqo2ronY9w4E"
   },
   "source": [
    "Nesta tarefa, vocês irão criar o seu próprio duelo de modelos, com o objetivo de superar os resultados apresentados em aula. O desafio é alcançar um desempenho superior ao que obtivemos, e para isso, será necessário aplicar todas as melhorias que vocês aprenderam ao longo dos módulos, utilizando a base de dados do Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG3kKnOQ91xm"
   },
   "source": [
    "**1. Escolha do Modelo:**\n",
    "Selecione um dos modelos que foram explorados nos duelos de modelos ao longo do curso. Pode ser SVM, Random Forest, XGBoost, ou qualquer outro que tenhamos abordado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     XGBoost\n",
    "\n",
    "     Por que XGBoost?\n",
    "\n",
    "     Excelente para dados tabulares\n",
    "\n",
    "     Lida bem com valores ausentes\n",
    "\n",
    "     Alta performance em competições\n",
    "\n",
    "     Permite ajuste fino de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrtylnB97mf"
   },
   "source": [
    "**2. Aperfeiçoamento:**\n",
    "**Aplique as técnicas que aprendemos para melhorar o desempenho do seu modelo:**\n",
    "\n",
    "**Hiperparâmetros:** Utilize GridSearchCV ou RandomSearchCV para encontrar os melhores parâmetros.\n",
    "\n",
    "**Cross Validation:** Avalie a robustez do modelo utilizando validação cruzada para garantir que ele generaliza bem.\n",
    "\n",
    "**Balanceamento de Classes:** Se o seu modelo lida com problemas de classes desbalanceadas, explore técnicas como SMOTE, undersampling ou oversampling.\n",
    "\n",
    "**Padronização e Normalização:** Lembre-se de padronizar os dados, especialmente se for usar modelos que são sensíveis à escala das variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÕES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# CARREGANDO DADOS\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# FEATURE ENGINEERING\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# CARREGANDO DADOS\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "\n",
    "for dataset in [train, test]:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = (dataset['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# TRATAMENTO DE VALORES AUSENTES (VERSÃO CORRETA)\n",
    "\n",
    "for dataset in [train, test]:\n",
    "    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].median())\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])\n",
    "\n",
    "# CONVERSÕES\n",
    "\n",
    "for dataset in [train, test]:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'male':0, 'female':1})\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Garantir mesmas colunas\n",
    "\n",
    "test = test.reindex(columns=train.columns, fill_value=0)\n",
    "\n",
    "# DEFININDO FEATURES\n",
    "\n",
    "features = [\n",
    "    'Pclass','Sex','Age','Fare',\n",
    "    'SibSp','Parch',\n",
    "    'FamilySize','IsAlone',\n",
    "    'Embarked_Q','Embarked_S'\n",
    "]\n",
    "\n",
    "X = train[features]\n",
    "y = train['Survived']\n",
    "X_test = test[features]\n",
    "\n",
    "# MODELO\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# PREVISÕES\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# CRIANDO SUBMISSION\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"submission.csv criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5nrSntC-GtC"
   },
   "source": [
    "**3. Submissão no Kaggle:**\n",
    "Treine o seu modelo com os dados de treino e gere as previsões para os dados de teste. Lembre-se de que o conjunto de teste não possui a variável alvo (y_test), pois a avaliação será feita com base nas submissões no Kaggle.\n",
    "Submeta suas previsões na competição do Titanic no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léo\\AppData\\Local\\Temp\\ipykernel_21528\\1528563792.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset['Age'].fillna(dataset['Age'].median(), inplace=True)\n",
      "C:\\Users\\Léo\\AppData\\Local\\Temp\\ipykernel_21528\\1528563792.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n",
      "C:\\Users\\Léo\\AppData\\Local\\Temp\\ipykernel_21528\\1528563792.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros:\n",
      "{'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 300, 'classifier__subsample': 1.0}\n",
      "\n",
      "Arquivo submission.csv criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# CARREGANDO DADOS DO KAGGLE\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "\n",
    "for dataset in [train, test]:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = (dataset['FamilySize'] == 1).astype(int)\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace(\n",
    "        ['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],\n",
    "        'Rare'\n",
    "    )\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# DEFININDO X E Y\n",
    "\n",
    "X = train.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "X_test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# TRATANDO VALORES AUSENTES\n",
    "\n",
    "for dataset in [X, X_test]:\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace=True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# FEATURES\n",
    "\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Sex', 'Embarked', 'Pclass', 'Title', 'IsAlone']\n",
    "\n",
    "# PREPROCESSAMENTO\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# MODELO\n",
    "\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [200, 300],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# TREINANDO NO TRAIN\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Melhores parâmetros:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# GERANDO PREVISÕES PARA TEST\n",
    "\n",
    "predictions = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# CRIANDO ARQUIVO SUBMISSION\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nArquivo submission.csv criado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3k5a5jD-M2Q"
   },
   "source": [
    "**4. Entrega:**\n",
    "Envie o código que você desenvolveu, detalhando cada etapa do seu processo de modelagem, explicando as escolhas feitas e como essas ajudaram a melhorar o modelo.\n",
    "\n",
    "Junto com o código, envie um print do seu score obtido na plataforma do Kaggle. Esse score será a sua métrica final de avaliação, mostrando como o seu modelo se compara com os demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Escolha do Modelo\n",
    "\n",
    "    Na primeira etapa, foi selecionado um algoritmo de classificação para resolver o problema proposto na competição Titanic. O modelo escolhido foi o Random Forest Classifier, por ser um algoritmo robusto, eficiente em dados tabulares e menos propenso a overfitting quando comparado a uma única árvore de decisão.\n",
    "\n",
    "    A escolha do modelo levou em consideração:\n",
    "\n",
    "    Boa performance em problemas de classificação\n",
    "\n",
    "    Capacidade de lidar com variáveis numéricas e categóricas\n",
    "\n",
    "    Estabilidade mesmo com pequenas variações nos dados\n",
    "\n",
    "    Facilidade de interpretação e implementação\n",
    "\n",
    "    O objetivo dessa etapa foi definir um modelo base sólido para iniciar o processo de otimização e melhoria de desempenho.\n",
    "\n",
    "    2. Aperfeiçoamento do Modelo\n",
    "\n",
    "    Na segunda etapa, foram aplicadas técnicas de melhoria com o objetivo de aumentar a capacidade preditiva do modelo.\n",
    "\n",
    "    Foram tratados valores ausentes para evitar erros durante o treinamento:\n",
    "\n",
    "    A variável Age foi preenchida com a mediana.\n",
    "\n",
    "    A variável Fare foi preenchida com a mediana.\n",
    "\n",
    "    A variável Embarked foi preenchida com a moda.\n",
    "\n",
    "    Esse tratamento garantiu consistência e completude do conjunto de dados.\n",
    "\n",
    "    Variáveis categóricas foram convertidas para formato numérico:\n",
    "\n",
    "    A variável Sex foi transformada em valores binários (0 e 1).\n",
    "\n",
    "    A variável Embarked foi transformada utilizando One-Hot Encoding.\n",
    "\n",
    "    Esse processo foi fundamental para permitir que o algoritmo processasse corretamente informações categóricas.\n",
    "\n",
    "    O modelo foi configurado com 200 árvores (n_estimators = 200), aumentando sua capacidade de generalização.\n",
    "\n",
    "    3. Submissão no Kaggle\n",
    "\n",
    "    Na terceira etapa, o modelo foi treinado utilizando o arquivo train.csv, que contém a variável alvo “Survived”.\n",
    "\n",
    "    Em seguida:\n",
    "\n",
    "    Foram geradas previsões utilizando o arquivo test.csv, que não possui a variável alvo.\n",
    "\n",
    "    Foi criado o arquivo submission.csv, contendo apenas duas colunas:\n",
    "\n",
    "    PassengerId\n",
    "\n",
    "    Survived\n",
    "\n",
    "    O arquivo foi submetido na plataforma Kaggle para avaliação.\n",
    "\n",
    "    A métrica utilizada pela competição é a accuracy, que mede a proporção de previsões corretas realizadas pelo modelo.\n",
    "\n",
    "    O score obtido na plataforma representa a capacidade de generalização do modelo em dados inéditos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnLbij2e-QLX"
   },
   "source": [
    "**5. Competição Saudável:**\n",
    "A ideia é trazer um senso de competição saudável, então não vale replicar exatamente o que fizemos na aula! Inove, explore novas combinações de parâmetros e técnicas, e mostre do que é capaz. O importante é exercitar o pensamento crítico e a capacidade de experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0LftJMB-Vlu"
   },
   "source": [
    "**Dicas Finais:**\n",
    "\n",
    "Seja criativo e tenha um olhar crítico sobre o que pode ser melhorado.\n",
    "Teste diferentes abordagens e não se prenda a um único caminho.\n",
    "Lembre-se de que, mais do que alcançar o melhor score, o objetivo é aprender e aplicar o conhecimento de forma prática e eficaz.\n",
    "Boa sorte! Estamos ansiosos para ver como cada um de vocês vai se sair nesse desafio e quais insights irão surgir dessa competição!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1hkFA6-XOM"
   },
   "source": [
    "Ao final dessa atividade vocês terão participado da primeira competição publica de ciência de dados de vocês = )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
